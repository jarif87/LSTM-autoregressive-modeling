{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4464700,"sourceType":"datasetVersion","datasetId":2613332}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:41.970987Z","iopub.execute_input":"2024-10-13T16:17:41.971650Z","iopub.status.idle":"2024-10-13T16:17:41.976545Z","shell.execute_reply.started":"2024-10-13T16:17:41.971582Z","shell.execute_reply":"2024-10-13T16:17:41.975530Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/hamlet-txt/hamlet_TXT_FolgerShakespeare.txt','r') as file:\n    text=file.read().lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:41.978075Z","iopub.execute_input":"2024-10-13T16:17:41.978369Z","iopub.status.idle":"2024-10-13T16:17:41.989900Z","shell.execute_reply.started":"2024-10-13T16:17:41.978337Z","shell.execute_reply":"2024-10-13T16:17:41.989127Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer=Tokenizer()\ntokenizer.fit_on_texts([text])\ntotal_words=len(tokenizer.word_index)+1\ntotal_words","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:41.991584Z","iopub.execute_input":"2024-10-13T16:17:41.991966Z","iopub.status.idle":"2024-10-13T16:17:42.026798Z","shell.execute_reply.started":"2024-10-13T16:17:41.991923Z","shell.execute_reply":"2024-10-13T16:17:42.025915Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"4751"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.027899Z","iopub.execute_input":"2024-10-13T16:17:42.028196Z","iopub.status.idle":"2024-10-13T16:17:42.065085Z","shell.execute_reply.started":"2024-10-13T16:17:42.028163Z","shell.execute_reply":"2024-10-13T16:17:42.064187Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'the': 1,\n 'and': 2,\n 'to': 3,\n 'of': 4,\n 'you': 5,\n 'a': 6,\n 'i': 7,\n 'my': 8,\n 'hamlet': 9,\n 'in': 10,\n 'it': 11,\n 'that': 12,\n 'is': 13,\n 'not': 14,\n 'his': 15,\n 'this': 16,\n 'with': 17,\n 'but': 18,\n 'he': 19,\n 'for': 20,\n 'your': 21,\n 'me': 22,\n 'as': 23,\n 'be': 24,\n 'lord': 25,\n 'what': 26,\n 'king': 27,\n 'him': 28,\n 'so': 29,\n 'have': 30,\n 'will': 31,\n 'horatio': 32,\n 'do': 33,\n 'no': 34,\n 'we': 35,\n 'on': 36,\n 'are': 37,\n 'all': 38,\n 'queen': 39,\n 'by': 40,\n 'our': 41,\n 'they': 42,\n 'polonius': 43,\n 'shall': 44,\n 'if': 45,\n 'or': 46,\n 'laertes': 47,\n 'o': 48,\n 'good': 49,\n 'thou': 50,\n 'come': 51,\n 'now': 52,\n 'from': 53,\n 'more': 54,\n 'let': 55,\n 'her': 56,\n 'ophelia': 57,\n 'how': 58,\n 'was': 59,\n 'thy': 60,\n \"'t\": 61,\n 'at': 62,\n 'like': 63,\n 'most': 64,\n 'would': 65,\n 'there': 66,\n 'them': 67,\n 'sir': 68,\n 'well': 69,\n 'rosencrantz': 70,\n 'know': 71,\n 'enter': 72,\n \"'tis\": 73,\n 'may': 74,\n \"th'\": 75,\n 'us': 76,\n 'go': 77,\n 'love': 78,\n 'then': 79,\n 'did': 80,\n 'hath': 81,\n 'very': 82,\n 'speak': 83,\n 'which': 84,\n 'why': 85,\n 'an': 86,\n 'must': 87,\n 'thee': 88,\n 'give': 89,\n 'guildenstern': 90,\n 'such': 91,\n 'upon': 92,\n 'am': 93,\n 'when': 94,\n 'out': 95,\n 'their': 96,\n 'make': 97,\n 'here': 98,\n \"i'll\": 99,\n 'man': 100,\n 'father': 101,\n 'say': 102,\n 'should': 103,\n 'she': 104,\n 'where': 105,\n 'some': 106,\n 'too': 107,\n 'much': 108,\n 'than': 109,\n 'think': 110,\n 'one': 111,\n 'these': 112,\n 'time': 113,\n 'see': 114,\n 'heaven': 115,\n 'marcellus': 116,\n 'had': 117,\n 'tell': 118,\n 'yet': 119,\n 'who': 120,\n 'thus': 121,\n 'play': 122,\n 'own': 123,\n 'ay': 124,\n 'mother': 125,\n 'take': 126,\n 'exits': 127,\n 'up': 128,\n 'nor': 129,\n 'exit': 130,\n 'osric': 131,\n 'gravedigger': 132,\n 'night': 133,\n 'look': 134,\n 'death': 135,\n 'can': 136,\n 'soul': 137,\n 'hear': 138,\n 'again': 139,\n 'life': 140,\n 'ghost': 141,\n 'god': 142,\n 'might': 143,\n 'whose': 144,\n 'nothing': 145,\n 'hold': 146,\n 'down': 147,\n 'dead': 148,\n 'indeed': 149,\n 'could': 150,\n 'made': 151,\n 'mine': 152,\n 'barnardo': 153,\n 'heart': 154,\n 'been': 155,\n 'dear': 156,\n 'cannot': 157,\n 'leave': 158,\n 'into': 159,\n 'other': 160,\n 'pray': 161,\n 'does': 162,\n 'doth': 163,\n 'nature': 164,\n 'never': 165,\n 'matter': 166,\n 'nay': 167,\n 'great': 168,\n 'were': 169,\n 'both': 170,\n 'player': 171,\n 'away': 172,\n 'even': 173,\n 'sweet': 174,\n 'first': 175,\n 'two': 176,\n 'against': 177,\n 'true': 178,\n 'world': 179,\n 'head': 180,\n 'earth': 181,\n 'though': 182,\n 'itself': 183,\n 'put': 184,\n 'players': 185,\n 'scene': 186,\n 'eyes': 187,\n 'part': 188,\n 'show': 189,\n 'call': 190,\n 'denmark': 191,\n 'son': 192,\n 'seen': 193,\n 'comes': 194,\n 'fear': 195,\n 'those': 196,\n 'done': 197,\n 'set': 198,\n 'madness': 199,\n \"i'\": 200,\n 'mad': 201,\n 'fortinbras': 202,\n 'england': 203,\n 'off': 204,\n 'fair': 205,\n 'day': 206,\n 'old': 207,\n 'within': 208,\n 'himself': 209,\n 'follow': 210,\n 'friends': 211,\n 'before': 212,\n 'still': 213,\n 'till': 214,\n 'poor': 215,\n 'means': 216,\n 'words': 217,\n 'reynaldo': 218,\n 'act': 219,\n 'once': 220,\n 'believe': 221,\n 'without': 222,\n 'hand': 223,\n 'blood': 224,\n 'about': 225,\n 'sword': 226,\n 'gentleman': 227,\n \"that's\": 228,\n 'little': 229,\n 'body': 230,\n 'else': 231,\n 'keep': 232,\n 'many': 233,\n 'makes': 234,\n 'long': 235,\n 'farewell': 236,\n 'welcome': 237,\n 'thing': 238,\n 'art': 239,\n 'young': 240,\n 'find': 241,\n 'thoughts': 242,\n \"father's\": 243,\n 'noble': 244,\n 'ear': 245,\n 'end': 246,\n \"there's\": 247,\n 'cause': 248,\n 'gertrude': 249,\n 'stand': 250,\n 'watch': 251,\n 'majesty': 252,\n 'hast': 253,\n 'use': 254,\n 'better': 255,\n 'aside': 256,\n 'faith': 257,\n 'drink': 258,\n 'youth': 259,\n 'marry': 260,\n 'speech': 261,\n 'since': 262,\n 'murder': 263,\n 'yourself': 264,\n 'ho': 265,\n 'therefore': 266,\n 'mark': 267,\n 'something': 268,\n 'state': 269,\n 'question': 270,\n 'eye': 271,\n \"o'er\": 272,\n 'bear': 273,\n 'tongue': 274,\n 'said': 275,\n 'daughter': 276,\n 'between': 277,\n 'friend': 278,\n 'gentlemen': 279,\n 'answer': 280,\n 'live': 281,\n 'last': 282,\n 'goes': 283,\n 'grace': 284,\n 'heard': 285,\n 'spirit': 286,\n 'grief': 287,\n 'reason': 288,\n 'after': 289,\n 'grave': 290,\n 'rest': 291,\n 'lady': 292,\n 'dost': 293,\n 'sings': 294,\n 'norway': 295,\n 'form': 296,\n 'gone': 297,\n 'air': 298,\n 'ever': 299,\n 'duty': 300,\n 'ourselves': 301,\n 'thine': 302,\n 'sense': 303,\n \"we'll\": 304,\n 'saw': 305,\n 'while': 306,\n 'hands': 307,\n 'none': 308,\n 'virtue': 309,\n 'sent': 310,\n 'late': 311,\n 'francisco': 312,\n 'bed': 313,\n 'haste': 314,\n 'has': 315,\n 'awhile': 316,\n 'same': 317,\n 'myself': 318,\n 'together': 319,\n 'stay': 320,\n 'thought': 321,\n 'work': 322,\n 'ere': 323,\n 'fire': 324,\n 'any': 325,\n 'voice': 326,\n 'oft': 327,\n 'being': 328,\n \"'twere\": 329,\n 'purpose': 330,\n 'further': 331,\n 'kind': 332,\n 'madam': 333,\n 'mind': 334,\n 'remember': 335,\n 'word': 336,\n 'sleep': 337,\n 'please': 338,\n 'men': 339,\n 'bring': 340,\n 'fit': 341,\n 'revenge': 342,\n 'brother': 343,\n 'ground': 344,\n 'honest': 345,\n 'tonight': 346,\n 'peace': 347,\n 'full': 348,\n \"e'en\": 349,\n 'business': 350,\n 'things': 351,\n 'doubt': 352,\n \"what's\": 353,\n 'best': 354,\n 'seem': 355,\n 'face': 356,\n 'name': 357,\n 'each': 358,\n 'foul': 359,\n 'near': 360,\n 'way': 361,\n 'wind': 362,\n 'free': 363,\n 'damned': 364,\n 'villain': 365,\n 'right': 366,\n 'ha': 367,\n 'another': 368,\n 'three': 369,\n 'thousand': 370,\n 'fortune': 371,\n \"hamlet's\": 372,\n 'captain': 373,\n 'thanks': 374,\n 'place': 375,\n 'ears': 376,\n 'almost': 377,\n 'soft': 378,\n 'arms': 379,\n 'takes': 380,\n \"let's\": 381,\n 'memory': 382,\n 'uncle': 383,\n 'news': 384,\n 'came': 385,\n 'alone': 386,\n 'excellent': 387,\n 'hell': 388,\n 'honor': 389,\n 'deed': 390,\n 'second': 391,\n 'neither': 392,\n 'given': 393,\n 'phrase': 394,\n 'command': 395,\n 'mean': 396,\n 'action': 397,\n 'alas': 398,\n 'aught': 399,\n \"he's\": 400,\n 'swear': 401,\n 'fine': 402,\n 'behind': 403,\n 'passion': 404,\n 'lie': 405,\n 'noise': 406,\n 'voltemand': 407,\n 'get': 408,\n 'meet': 409,\n 'sight': 410,\n 'strange': 411,\n 'fell': 412,\n 'lost': 413,\n 'through': 414,\n 'walk': 415,\n 'others': 416,\n 'woe': 417,\n 'far': 418,\n 'seek': 419,\n 'breath': 420,\n 'back': 421,\n 'fellow': 422,\n 'grow': 423,\n 'judgment': 424,\n 'light': 425,\n 'custom': 426,\n 'draw': 427,\n 'sure': 428,\n 'offense': 429,\n 'lay': 430,\n 'letters': 431,\n 'age': 432,\n 'thank': 433,\n 'gave': 434,\n 'fall': 435,\n 'devil': 436,\n 'says': 437,\n 'sit': 438,\n 'break': 439,\n 'looks': 440,\n 'charge': 441,\n 'pale': 442,\n 'particular': 443,\n 'known': 444,\n 'unto': 445,\n 'sun': 446,\n 'coming': 447,\n 'sea': 448,\n 'wherein': 449,\n 'power': 450,\n 'flourish': 451,\n 'joy': 452,\n 'wife': 453,\n 'less': 454,\n 'black': 455,\n 'truly': 456,\n 'shows': 457,\n 'desire': 458,\n \"king's\": 459,\n 'tears': 460,\n 'lordship': 461,\n 'fashion': 462,\n 'service': 463,\n 'shame': 464,\n 'wilt': 465,\n 'adieu': 466,\n 'heavens': 467,\n 'hither': 468,\n 'help': 469,\n 'times': 470,\n \"here's\": 471,\n \"'s\": 472,\n 'falls': 473,\n \"o'\": 474,\n 'hope': 475,\n 'gives': 476,\n 'arras': 477,\n 'quick': 478,\n 'conscience': 479,\n 'husband': 480,\n 'skull': 481,\n '2': 482,\n 'danish': 483,\n 'court': 484,\n 'cornelius': 485,\n 'prologue': 486,\n 'attendants': 487,\n 'hour': 488,\n 'law': 489,\n 'list': 490,\n 'wholesome': 491,\n 'loves': 492,\n 'whole': 493,\n 'sister': 494,\n 'marriage': 495,\n 'lose': 496,\n 'beg': 497,\n 'pardon': 498,\n 'beseech': 499,\n 'dust': 500,\n 'common': 501,\n 'die': 502,\n 'obey': 503,\n 'rank': 504,\n 'top': 505,\n 'wisdom': 506,\n 'shot': 507,\n 'enough': 508,\n 'lies': 509,\n 'effect': 510,\n 'every': 511,\n 'understand': 512,\n 'fool': 513,\n 'heavy': 514,\n 'general': 515,\n 'table': 516,\n 'needs': 517,\n 'music': 518,\n 'receive': 519,\n 'ill': 520,\n 'loved': 521,\n 'speaks': 522,\n 'begin': 523,\n 'pyrrhus': 524,\n 'bloody': 525,\n 'turn': 526,\n 'killed': 527,\n 'poison': 528,\n 'dies': 529,\n 'messenger': 530,\n 'drowned': 531,\n 'cup': 532,\n 'claudius': 533,\n 'soldiers': 534,\n 'ambassadors': 535,\n '1': 536,\n 'struck': 537,\n 'cold': 538,\n 'bid': 539,\n 'dane': 540,\n 'piece': 541,\n 'star': 542,\n \"t'\": 543,\n 'buried': 544,\n 'cast': 545,\n 'toward': 546,\n 'sealed': 547,\n 'stood': 548,\n 'hot': 549,\n 'sound': 550,\n 'cock': 551,\n 'wrong': 552,\n 'guilty': 553,\n 'whether': 554,\n 'truth': 555,\n 'season': 556,\n 'dare': 557,\n 'gracious': 558,\n 'dumb': 559,\n \"brother's\": 560,\n 'sorrow': 561,\n 'dream': 562,\n 'wouldst': 563,\n 'mouth': 564,\n 'confess': 565,\n 'seems': 566,\n 'fie': 567,\n 'note': 568,\n 'health': 569,\n 'woman': 570,\n 'beast': 571,\n 'discourse': 572,\n 'longer': 573,\n 'wicked': 574,\n 'prithee': 575,\n \"mother's\": 576,\n 'forth': 577,\n 'point': 578,\n 'beard': 579,\n 'fare': 580,\n 'withal': 581,\n 'choice': 582,\n 'maid': 583,\n 'beauty': 584,\n 'double': 585,\n 'dull': 586,\n 'false': 587,\n 'vows': 588,\n 'trumpets': 589,\n 'shape': 590,\n 'days': 591,\n 'prison': 592,\n 'fat': 593,\n 'crown': 594,\n 'went': 595,\n 'already': 596,\n 'mercy': 597,\n 'lack': 598,\n 'touch': 599,\n 'took': 600,\n 'move': 601,\n 'brought': 602,\n 'whom': 603,\n 'home': 604,\n 'round': 605,\n 'herself': 606,\n 'try': 607,\n 'either': 608,\n 'bad': 609,\n 'ambition': 610,\n 'laugh': 611,\n 'brains': 612,\n 'only': 613,\n 'anon': 614,\n 'proof': 615,\n 'feed': 616,\n 'slain': 617,\n 'laid': 618,\n 'hit': 619,\n 'foils': 620,\n 'water': 621,\n 'prince': 622,\n 'doctor': 623,\n 'lords': 624,\n 'twelve': 625,\n 'sick': 626,\n 'quiet': 627,\n 'course': 628,\n 'figure': 629,\n 'warlike': 630,\n 'march': 631,\n 'thyself': 632,\n 'land': 633,\n 'terms': 634,\n 'motive': 635,\n 'spirits': 636,\n 'trumpet': 637,\n 'stir': 638,\n 'impart': 639,\n 'morning': 640,\n 'kingdom': 641,\n 'follows': 642,\n 'writ': 643,\n 'told': 644,\n 'dread': 645,\n 'return': 646,\n 'france': 647,\n 'hard': 648,\n 'color': 649,\n 'visage': 650,\n 'bound': 651,\n 'fault': 652,\n 'throw': 653,\n 'gentle': 654,\n 'flesh': 655,\n 'ah': 656,\n 'grows': 657,\n 'visit': 658,\n 'disposition': 659,\n 'report': 660,\n 'methinks': 661,\n 'knew': 662,\n 'honored': 663,\n 'yes': 664,\n 'perchance': 665,\n 'silence': 666,\n 'perhaps': 667,\n 'safety': 668,\n 'affection': 669,\n 'danger': 670,\n 'moon': 671,\n 'blessing': 672,\n \"man's\": 673,\n 'audience': 674,\n 'circumstance': 675,\n 'making': 676,\n 'keeps': 677,\n 'choose': 678,\n \"fortune's\": 679,\n 'souls': 680,\n 'base': 681,\n 'puts': 682,\n 'brain': 683,\n 'cries': 684,\n 'hearing': 685,\n 'shalt': 686,\n 'fast': 687,\n 'didst': 688,\n 'wits': 689,\n 'gifts': 690,\n 'wit': 691,\n 'natural': 692,\n 'brief': 693,\n 'sudden': 694,\n 'vile': 695,\n 'knave': 696,\n 'under': 697,\n 'stage': 698,\n 'fingers': 699,\n 'liberty': 700,\n 'mass': 701,\n 'arm': 702,\n 'over': 703,\n 'ecstasy': 704,\n 'hide': 705,\n 'found': 706,\n 'whereon': 707,\n 'commission': 708,\n 'pass': 709,\n 'read': 710,\n 'reads': 711,\n 'short': 712,\n 'presently': 713,\n 'honesty': 714,\n 'anything': 715,\n 'save': 716,\n 'bodies': 717,\n 'cry': 718,\n 'sing': 719,\n 'themselves': 720,\n 'yours': 721,\n 'french': 722,\n 'fly': 723,\n 'horse': 724,\n 'treason': 725,\n 'mortal': 726,\n 'conceit': 727,\n 'drown': 728,\n 'dangerous': 729,\n 'nunnery': 730,\n 'christian': 731,\n 'eat': 732,\n 'patience': 733,\n 'half': 734,\n 'year': 735,\n 'forgot': 736,\n 'door': 737,\n 'next': 738,\n 'bore': 739,\n 'wager': 740,\n 'alexander': 741,\n \"woo't\": 742,\n 'carriages': 743,\n 'married': 744,\n 'lucianus': 745,\n 'gonzago': 746,\n 'divinity': 747,\n 'officers': 748,\n 'unfold': 749,\n 'guard': 750,\n 'twice': 751,\n \"'twill\": 752,\n 'wonder': 753,\n 'knows': 754,\n 'cannon': 755,\n 'image': 756,\n 'lands': 757,\n 'returned': 758,\n 'strong': 759,\n 'main': 760,\n 'armed': 761,\n 'high': 762,\n 'stars': 763,\n 'stands': 764,\n 'ease': 765,\n 'treasure': 766,\n 'stop': 767,\n 'violence': 768,\n 'throat': 769,\n 'herein': 770,\n \"'gainst\": 771,\n 'birth': 772,\n 'consent': 773,\n 'brow': 774,\n 'discretion': 775,\n 'remembrance': 776,\n 'funeral': 777,\n 'freely': 778,\n 'affair': 779,\n 'thinking': 780,\n 'frame': 781,\n 'giving': 782,\n 'commend': 783,\n 'native': 784,\n 'favor': 785,\n 'cousin': 786,\n 'clouds': 787,\n 'hang': 788,\n 'lives': 789,\n 'died': 790,\n 'wittenberg': 791,\n 'courtier': 792,\n 'sits': 793,\n 'drinks': 794,\n 'months': 795,\n 'grown': 796,\n 'month': 797,\n 'speed': 798,\n 'incestuous': 799,\n 'glad': 800,\n 'forget': 801,\n 'change': 802,\n 'elsinore': 803,\n 'teach': 804,\n 'deep': 805,\n 'mock': 806,\n 'thrift': 807,\n 'thrice': 808,\n 'length': 809,\n 'kept': 810,\n 'methought': 811,\n 'motion': 812,\n 'looked': 813,\n 'countenance': 814,\n 'warrant': 815,\n 'assume': 816,\n 'person': 817,\n '3': 818,\n 'wide': 819,\n 'occasion': 820,\n 'entertainment': 821,\n 'new': 822,\n 'censure': 823,\n 'habit': 824,\n 'above': 825,\n 'humbly': 826,\n 'tend': 827,\n 'pay': 828,\n 'tender': 829,\n 'heat': 830,\n 'leisure': 831,\n '4': 832,\n 'infinite': 833,\n 'royal': 834,\n 'bones': 835,\n 'horrible': 836,\n 'beneath': 837,\n 'desperate': 838,\n 'imagination': 839,\n 'direct': 840,\n 'lead': 841,\n 'pity': 842,\n 'lend': 843,\n 'certain': 844,\n 'house': 845,\n 'tale': 846,\n 'start': 847,\n 'unnatural': 848,\n 'sleeping': 849,\n 'angel': 850,\n 'cursed': 851,\n 'holds': 852,\n 'instant': 853,\n 'bosom': 854,\n 'distracted': 855,\n 'commandment': 856,\n 'book': 857,\n 'secret': 858,\n 'wild': 859,\n 'sorry': 860,\n 'seeing': 861,\n 'need': 862,\n 'drift': 863,\n 'breathe': 864,\n 'closes': 865,\n 'consequence': 866,\n 'closet': 867,\n 'sigh': 868,\n 'turned': 869,\n 'violent': 870,\n 'property': 871,\n 'sith': 872,\n 'polack': 873,\n 'sends': 874,\n 'rather': 875,\n 'white': 876,\n 'letter': 877,\n 'fain': 878,\n 'thence': 879,\n 'four': 880,\n 'ten': 881,\n 'dreams': 882,\n 'quality': 883,\n 'argument': 884,\n 'possible': 885,\n 'twenty': 886,\n 'lest': 887,\n \"'twas\": 888,\n 'ass': 889,\n 'pastoral': 890,\n 'straight': 891,\n 'modesty': 892,\n 'cunning': 893,\n 'priam': 894,\n 'pause': 895,\n 'sleeps': 896,\n 'hecuba': 897,\n 'tomorrow': 898,\n 'slave': 899,\n 'weep': 900,\n 'calls': 901,\n 'pate': 902,\n 'bestow': 903,\n 'blame': 904,\n 'withdraw': 905,\n 'snow': 906,\n 'rose': 907,\n 'quite': 908,\n 'wretched': 909,\n 'send': 910,\n 'quantity': 911,\n 'ready': 912,\n 'wear': 913,\n 'kill': 914,\n 'oh': 915,\n 'maker': 916,\n 'leaves': 917,\n 'imports': 918,\n 'hence': 919,\n 'weeds': 920,\n 'lights': 921,\n 'stronger': 922,\n 'whereto': 923,\n 'pleasure': 924,\n 'rapier': 925,\n 'poisoned': 926,\n 'fight': 927,\n 'practice': 928,\n 'burial': 929,\n 'spade': 930,\n 'gallows': 931,\n 'six': 932,\n 'shakespeare': 933,\n 'army': 934,\n 'sailors': 935,\n 'bitter': 936,\n 'appeared': 937,\n 'fantasy': 938,\n 'touching': 939,\n 'along': 940,\n 'appear': 941,\n 'story': 942,\n 'nights': 943,\n 'beating': 944,\n 'sometimes': 945,\n 'offended': 946,\n 'armor': 947,\n 'ambitious': 948,\n 'gross': 949,\n 'scope': 950,\n 'subject': 951,\n 'sore': 952,\n 'recover': 953,\n 'chief': 954,\n 'sort': 955,\n 'doomsday': 956,\n 'lo': 957,\n 'avoid': 958,\n 'offer': 959,\n 'morn': 960,\n 'present': 961,\n 'dew': 962,\n 'hill': 963,\n 'advice': 964,\n 'green': 965,\n 'wisest': 966,\n 'sometime': 967,\n 'delight': 968,\n 'worth': 969,\n 'importing': 970,\n 'ourself': 971,\n 'hears': 972,\n 'paper': 973,\n 'heartily': 974,\n 'suit': 975,\n 'bend': 976,\n 'bow': 977,\n 'slow': 978,\n 'passing': 979,\n 'suits': 980,\n 'solemn': 981,\n 'forms': 982,\n 'shapes': 983,\n 'understanding': 984,\n 'theme': 985,\n 'cried': 986,\n 'corse': 987,\n 'cheer': 988,\n 'loving': 989,\n 'smiling': 990,\n 'rouse': 991,\n 'fixed': 992,\n 'flat': 993,\n 'uses': 994,\n 'winds': 995,\n 'followed': 996,\n 'hercules': 997,\n 'salt': 998,\n 'left': 999,\n 'enemy': 1000,\n ...}"},"metadata":{}}]},{"cell_type":"code","source":"input_sequences=[]\nfor line in text.split('\\n'):\n    token_list=tokenizer.texts_to_sequences([line])[0]\n    for i in range(1,len(token_list)):\n        n_gram_sequence=token_list[:i+1]\n        input_sequences.append(n_gram_sequence)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.067027Z","iopub.execute_input":"2024-10-13T16:17:42.067349Z","iopub.status.idle":"2024-10-13T16:17:42.164928Z","shell.execute_reply.started":"2024-10-13T16:17:42.067315Z","shell.execute_reply":"2024-10-13T16:17:42.164075Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"max_sequence_len=max([len(x) for x in input_sequences])\nmax_sequence_len","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.166142Z","iopub.execute_input":"2024-10-13T16:17:42.166524Z","iopub.status.idle":"2024-10-13T16:17:42.175634Z","shell.execute_reply.started":"2024-10-13T16:17:42.166481Z","shell.execute_reply":"2024-10-13T16:17:42.174681Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"code","source":"input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre'))\ninput_sequences","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.176818Z","iopub.execute_input":"2024-10-13T16:17:42.177117Z","iopub.status.idle":"2024-10-13T16:17:42.290147Z","shell.execute_reply.started":"2024-10-13T16:17:42.177086Z","shell.execute_reply":"2024-10-13T16:17:42.289241Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([[   0,    0,    0, ...,    0,   40, 1944],\n       [   0,    0,    0, ...,   40, 1944,  933],\n       [   0,    0,    0, ...,    0, 1945,   40],\n       ...,\n       [   0,    0,    0, ...,    0, 1937,   37],\n       [   0,    0,    0, ..., 1937,   37,  507],\n       [   0,    0,    0, ...,   37,  507,  204]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nx,y=input_sequences[:,:-1],input_sequences[:,-1]","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.291415Z","iopub.execute_input":"2024-10-13T16:17:42.291806Z","iopub.status.idle":"2024-10-13T16:17:42.296495Z","shell.execute_reply.started":"2024-10-13T16:17:42.291765Z","shell.execute_reply":"2024-10-13T16:17:42.295388Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"y=tf.keras.utils.to_categorical(y,num_classes=total_words)\ny","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.297837Z","iopub.execute_input":"2024-10-13T16:17:42.298144Z","iopub.status.idle":"2024-10-13T16:17:42.374888Z","shell.execute_reply.started":"2024-10-13T16:17:42.298112Z","shell.execute_reply":"2024-10-13T16:17:42.373880Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.376290Z","iopub.execute_input":"2024-10-13T16:17:42.376990Z","iopub.status.idle":"2024-10-13T16:17:42.987148Z","shell.execute_reply.started":"2024-10-13T16:17:42.376944Z","shell.execute_reply":"2024-10-13T16:17:42.986307Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.990456Z","iopub.execute_input":"2024-10-13T16:17:42.990862Z","iopub.status.idle":"2024-10-13T16:17:42.995513Z","shell.execute_reply.started":"2024-10-13T16:17:42.990821Z","shell.execute_reply":"2024-10-13T16:17:42.994649Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout,GRU\n\n## Define the model\nmodel=Sequential()\nmodel.add(Embedding(total_words,100,input_shape=(max_sequence_len-1,)))\nmodel.add(LSTM(150,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dense(total_words,activation=\"softmax\"))\n\n# #Compile the model\nmodel.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:42.996692Z","iopub.execute_input":"2024-10-13T16:17:42.997044Z","iopub.status.idle":"2024-10-13T16:17:43.087785Z","shell.execute_reply.started":"2024-10-13T16:17:42.997002Z","shell.execute_reply":"2024-10-13T16:17:43.086911Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m475,100\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4751\u001b[0m)           │       \u001b[38;5;34m479,851\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4751</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">479,851</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,205,951\u001b[0m (4.60 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205,951</span> (4.60 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,205,951\u001b[0m (4.60 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205,951</span> (4.60 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"## GRU RNN\n## Define the model\nmodel2=Sequential()\nmodel2.add(Embedding(input_dim=total_words,output_dim=100,input_shape=(max_sequence_len-1,)))\nmodel2.add(GRU(150,return_sequences=True))\nmodel2.add(Dropout(0.2))\nmodel2.add(GRU(100))\nmodel2.add(Dense(total_words,activation=\"softmax\"))\n\n# #Compile the model\nmodel2.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:43.088954Z","iopub.execute_input":"2024-10-13T16:17:43.089269Z","iopub.status.idle":"2024-10-13T16:17:43.171851Z","shell.execute_reply.started":"2024-10-13T16:17:43.089237Z","shell.execute_reply":"2024-10-13T16:17:43.171009Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m475,100\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m113,400\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m75,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4751\u001b[0m)           │       \u001b[38;5;34m479,851\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">475,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">113,400</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4751</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">479,851</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,143,951\u001b[0m (4.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,143,951</span> (4.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,143,951\u001b[0m (4.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,143,951</span> (4.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"## Train the model\nhistory=model.fit(x_train,y_train,epochs=80,validation_data=(x_test,y_test),verbose=1,callbacks=[early_stopping])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:17:43.172978Z","iopub.execute_input":"2024-10-13T16:17:43.173260Z","iopub.status.idle":"2024-10-13T16:22:57.274861Z","shell.execute_reply.started":"2024-10-13T16:17:43.173228Z","shell.execute_reply":"2024-10-13T16:22:57.273839Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.0307 - loss: 7.1077 - val_accuracy: 0.0336 - val_loss: 6.6829\nEpoch 2/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0355 - loss: 6.4326 - val_accuracy: 0.0383 - val_loss: 6.7597\nEpoch 3/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0447 - loss: 6.2609 - val_accuracy: 0.0485 - val_loss: 6.7880\nEpoch 4/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0519 - loss: 6.1254 - val_accuracy: 0.0481 - val_loss: 6.7775\nEpoch 5/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.0570 - loss: 5.9696 - val_accuracy: 0.0558 - val_loss: 6.8154\nEpoch 6/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0670 - loss: 5.8466 - val_accuracy: 0.0594 - val_loss: 6.8363\nEpoch 7/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0765 - loss: 5.6755 - val_accuracy: 0.0602 - val_loss: 6.8931\nEpoch 8/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0841 - loss: 5.5330 - val_accuracy: 0.0653 - val_loss: 6.9648\nEpoch 9/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.0951 - loss: 5.3865 - val_accuracy: 0.0697 - val_loss: 7.0300\nEpoch 10/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1046 - loss: 5.2739 - val_accuracy: 0.0709 - val_loss: 7.1238\nEpoch 11/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1102 - loss: 5.1285 - val_accuracy: 0.0697 - val_loss: 7.1834\nEpoch 12/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1162 - loss: 4.9812 - val_accuracy: 0.0689 - val_loss: 7.2352\nEpoch 13/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1208 - loss: 4.8931 - val_accuracy: 0.0680 - val_loss: 7.3890\nEpoch 14/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1280 - loss: 4.7531 - val_accuracy: 0.0702 - val_loss: 7.5330\nEpoch 15/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1319 - loss: 4.6416 - val_accuracy: 0.0724 - val_loss: 7.6493\nEpoch 16/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1357 - loss: 4.5580 - val_accuracy: 0.0711 - val_loss: 7.7943\nEpoch 17/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1443 - loss: 4.4442 - val_accuracy: 0.0729 - val_loss: 7.9346\nEpoch 18/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1551 - loss: 4.3531 - val_accuracy: 0.0678 - val_loss: 8.0351\nEpoch 19/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1668 - loss: 4.2362 - val_accuracy: 0.0691 - val_loss: 8.1569\nEpoch 20/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1752 - loss: 4.1461 - val_accuracy: 0.0686 - val_loss: 8.3121\nEpoch 21/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1924 - loss: 4.0427 - val_accuracy: 0.0673 - val_loss: 8.4496\nEpoch 22/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2023 - loss: 3.9597 - val_accuracy: 0.0673 - val_loss: 8.5841\nEpoch 23/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.2143 - loss: 3.8687 - val_accuracy: 0.0671 - val_loss: 8.7078\nEpoch 24/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.2205 - loss: 3.8033 - val_accuracy: 0.0677 - val_loss: 8.8317\nEpoch 25/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.2386 - loss: 3.7143 - val_accuracy: 0.0682 - val_loss: 8.9477\nEpoch 26/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2495 - loss: 3.6530 - val_accuracy: 0.0664 - val_loss: 9.0617\nEpoch 27/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.2537 - loss: 3.5968 - val_accuracy: 0.0660 - val_loss: 9.1610\nEpoch 28/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2711 - loss: 3.5378 - val_accuracy: 0.0658 - val_loss: 9.2836\nEpoch 29/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2773 - loss: 3.4860 - val_accuracy: 0.0640 - val_loss: 9.3966\nEpoch 30/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2857 - loss: 3.4198 - val_accuracy: 0.0651 - val_loss: 9.5059\nEpoch 31/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2965 - loss: 3.3592 - val_accuracy: 0.0631 - val_loss: 9.5810\nEpoch 32/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2984 - loss: 3.3146 - val_accuracy: 0.0625 - val_loss: 9.6949\nEpoch 33/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3054 - loss: 3.2755 - val_accuracy: 0.0624 - val_loss: 9.7858\nEpoch 34/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3207 - loss: 3.2177 - val_accuracy: 0.0596 - val_loss: 9.9001\nEpoch 35/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3303 - loss: 3.1577 - val_accuracy: 0.0587 - val_loss: 9.9741\nEpoch 36/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3315 - loss: 3.1314 - val_accuracy: 0.0602 - val_loss: 10.0587\nEpoch 37/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.3454 - loss: 3.0572 - val_accuracy: 0.0594 - val_loss: 10.1514\nEpoch 38/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3571 - loss: 3.0025 - val_accuracy: 0.0587 - val_loss: 10.2312\nEpoch 39/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3613 - loss: 2.9759 - val_accuracy: 0.0569 - val_loss: 10.2773\nEpoch 40/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.3725 - loss: 2.9383 - val_accuracy: 0.0602 - val_loss: 10.3600\nEpoch 41/80\n\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.3715 - loss: 2.9132 - val_accuracy: 0.0584 - val_loss: 10.4420\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to predict the next word\ndef predict_next_word(model, tokenizer, text, max_sequence_len):\n    token_list = tokenizer.texts_to_sequences([text])[0]\n    if len(token_list) >= max_sequence_len:\n        token_list = token_list[-(max_sequence_len-1):]  # Ensure the sequence length matches max_sequence_len-1\n    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n    predicted = model.predict(token_list, verbose=0)\n    predicted_word_index = np.argmax(predicted, axis=1)\n    for word, index in tokenizer.word_index.items():\n        if index == predicted_word_index:\n            return word\n    return None","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:23:51.986776Z","iopub.execute_input":"2024-10-13T16:23:51.987707Z","iopub.status.idle":"2024-10-13T16:23:51.994168Z","shell.execute_reply.started":"2024-10-13T16:23:51.987656Z","shell.execute_reply":"2024-10-13T16:23:51.993267Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"input_text=\"Enter Barnardo and Francisco two\"\nprint(f\"Input text:{input_text}\")\nmax_sequence_len=model.input_shape[1]+1\nnext_word=predict_next_word(model,tokenizer,input_text,max_sequence_len)\nprint(f\"Next Word PRediction:{next_word}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:25:25.429543Z","iopub.execute_input":"2024-10-13T16:25:25.429985Z","iopub.status.idle":"2024-10-13T16:25:25.493118Z","shell.execute_reply.started":"2024-10-13T16:25:25.429932Z","shell.execute_reply":"2024-10-13T16:25:25.492120Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Input text:Enter Barnardo and Francisco two\nNext Word PRediction:the\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"next_word_lstm.h5\")\n## Save the tokenizer\nimport pickle\nwith open('tokenizer.pickle','wb') as handle:\n    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T16:24:12.821135Z","iopub.execute_input":"2024-10-13T16:24:12.821527Z","iopub.status.idle":"2024-10-13T16:24:12.885173Z","shell.execute_reply.started":"2024-10-13T16:24:12.821487Z","shell.execute_reply":"2024-10-13T16:24:12.884154Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}